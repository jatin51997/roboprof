1Artificial Intelligence: 
Adversarial Search2Motivation
GO
chess
 tic-tac-toe3Today
‚óºState Space Search for Game Playing
‚ùëMiniMax
‚ùëAlpha -beta pruning
‚ùëStochastic Games
‚óºWhere we are today
5Adversarial Search
‚óºClassical application for heuristic search
‚ùësimple games: exhaustively searchable
‚ùëcomplex games: only partial search possible
‚ùëadditional problem: playing against opponent
‚óºHere, we look at 2 -player adversarial games
‚ùëwin, lose, or tie6Types of Games
‚óºPerfect Information
‚ùëA game with the perfect information is that in which agents can 
look into the complete board. Agents have all the information about 
the game, and they can see each other moves also. 
‚ùëExamples: Chess, Checkers, Go, etc.
‚óºImperfect Information
‚ùëGame state only partially observable, choices by opponent are not 
visible (hidden)
‚ùëExample: Battleship, Stratego, many card games, etc.7Types of Games (II)
‚óºDeterministic games
‚ùëNo games of chance (e.g., rolling dice)
‚ùëExamples: Chess, Tic -Tac-Toe, Go, etc.
‚óºNon-deterministic games
‚ùëGames with unpredictable (random) events (involving chance or luck)
‚ùëExample: Backgammon, Monopoly, Poker, etc.8Types of Games (III)
‚óºZero-Sum Game
‚ùëIf the total gains of one player are added up, and the 
total losses are subtracted, they will sum to zero
(example: cutting a cake) 
‚ùëA gain by one player must be matched by a loss by the 
other player
‚ùëOne player tries to maximize a single value, the other 
player tries to minimize it
‚ùëExamples: Checkers, Chess, etc.
‚óºNon-Zero-Sum Game
‚ùëWin-Win or Lose -Lose type games
‚ùëFamous example: The Prisoner‚Äôs Dilemma
https://en.wikipedia.org/wiki/Prisoner%27s_dilemma9Today
‚óºState Space Search for Game Playing
‚ùëMiniMax
‚ùëAlpha -beta pruning
‚ùëStochastic games
‚óºWhere we are today
10Example: Game of Nim
‚óºRules
‚ùë2 players start with a pile of tokens
‚ùëmove: split (any) existing pile into two non-empty
differently -sized piles
‚ùëgame ends when no pile can be unevenly split
‚ùëplayer who cannot make his move loses11State Space of Game Nim
‚óºstart with one pile of tokens
‚óºeach step has to divide one pile 
of tokens into 2 non -empty piles 
of different size
‚óºplayer without a move left loses 
game
source: G. Luger (2005) 12MiniMax Search
‚óºGame between two opponents, MIN and MAX
‚ùëMAX tries to win, and 
‚ùëMIN tries to minimize MAX‚Äôs score
‚óºExisting heuristic search methods do not work
‚ùëwould require a helpful opponent
‚ùëNeed to incorporate ‚Äúhostile‚Äù moves into search strategy13Exhaustive MiniMax Search 
‚óºFor small games where exhaustive search is feasible
‚óºProcedure:
1.build complete game tree
2.label each level according to player‚Äôs turn (MAX or MIN)
3.label leaves with a utility function to determine the outcome 
of the game
‚óºe.g., (0, 1) or ( -1, 0, 1)
4.propagate this value up:
‚óºif parent=MAX, give it max value of children
‚óºif parent=MIN, give it min value of children
5.Select best next move for player at root as the move leading 
to the child with the highest value (for MAX) or lowest 
values (for MIN) 14
Exhaustive MiniMax for Nim
Bold lines indicate
forced win for MAX 
source: G. Luger (2005) 0: win for MIN
1: win for MAX15n-ply MiniMax with Heuristic
‚óºExhaustive search for interesting games is rarely 
feasible
‚óºSearch only to predefined level
‚ùëcalled n-ply look -ahead
‚ùën is number of levels
‚óºNo exhaustive search
‚ùënodes evaluated with heuristics and not win/loss
‚ùëindicates best state that can be reached
‚ùëhorizon effect
‚óºGames with opponent
‚ùësimple strategy: try to maximize difference between 
players using a heuristic function e(n)Heuristic Function for 2 -player games
‚óºsimple strategy: 
‚ùëtry to maximize difference between MAX‚Äôs game and MIN‚Äôs 
game 
‚óºtypically called e(n)
‚óºe(n) is a heuristic that estimates how favorable a 
node n is for MAX
‚ùëe(n) > 0 --> n is favorable to MAX 
‚ùëe(n) < 0 --> n is favorable to MIN 
‚ùëe(n) = 0 --> n is neutral 
16Choosing a Heuristic Function e(n)
17
18
MiniMax with Fixed Ply Depth
Leaf nodes show the actual heuristic value e(n)
source: G. Luger (2005) 19
MiniMax with Fixed Ply Depth
Leaf nodes show the actual heuristic value e(n)
Internal nodes show back-upheuristic value
source: G. Luger (2005) max(2,3) = 3
max(5,9) = 9
‚Ä¶.
20
MiniMax with Fixed Ply Depth
Leaf nodes show the actual heuristic value e(n)
Internal nodes show back-upheuristic value
source: G. Luger (2005) min(3,9) = 3
min(0,7) = 9
min(2,6) = 221
MiniMax with Fixed Ply Depth
Leaf nodes show the actual heuristic value e(n)
Internal nodes show back-upheuristic value
source: G. Luger (2005) max(3, 0, 2) = 322
MiniMax with Fixed Ply Depth
Leaf nodes show the actual heuristic value e(n)
Internal nodes show back-upheuristic value
source: G. Luger (2005) Best next move Example: e(n) for Tic -Tac-Toe
‚óºPossible e(n)
number of rows, columns, and diagonals open for MAX
-number of rows, columns, and diagonals open for MIN  
+ , if n is a forced win for MAX
- , if n is a forced win for MIN
e(n) = 8-8 = 0 e(n) = 6-4 = 2e(n) = 3-3 = 0
23e(n) =   24
More examples‚Ä¶
source: G. Luger (2005) 25
Two-ply MiniMax for Opening Move
source: G. Luger (2005) Tic-Tac-Toe tree
at horizon = 226
Two-ply MiniMax: MAX‚Äôs possible 2ndmoves
source: G. Luger (2005) 27
Two-ply minimax: MAX‚Äôs move at end
source: G. Luger (2005) 28Today
‚óºState Space Search for Game Playing
‚ùëMiniMax
‚ùëAlpha -beta pruning
‚ùëStochastic games
‚óºWhere we are today
29Alpha -Beta Pruning
‚óºOptimization over MiniMax, that:
‚ùëignores (cuts off, prunes) branches of the tree 
that cannot possibly lead to a better solution
‚ùëreduces branching factor
‚ùëallows deeper search with same effort30Alpha -Beta Pruning: Example 1
‚óºWith MiniMax, we look at all possible nodes at the n-ply depth
‚óºWith Œ± -Œ≤ pruning, we ignore branches that could not possibly 
contribute to the final decision
B will be >= 5
So we can ignore B‚Äôs right 
branch, because A must be 3
D will be <= 0
But C will be >= 3
So we can ignore D‚Äôs right 
branch
E will be <= 2.
So we can ignore E‚Äôs right 
branch
Because C will be 3.
source: G. Luger (2005) A=min(3, max(5,?))C=max(3, min(0,?), min(2,?))Alpha -Beta Pruning Algorithm
31‚óºŒ± :lower bound on the final backed -up value.
‚óºŒ≤ :upper bound on the final backed -up value.
‚óºAlpha pruning: 
‚ùëeg.  if MAX node's Œ±= 6, then the search can prune branches from a MIN 
descendant that has a Œ≤<= 6.  
‚ùëif child Œ≤<= ancestor Œ±‚Üíprune
‚ùë
‚óºBeta pruning: 
‚ùëeg. if a MIN node's Œ≤= 6, then the search can prune branches from a MAX 
descendant that has an Œ±>= 6. 
‚ùëif ancestor Œ≤<= child Œ±‚Üíprunevalue ‚â•6 
value‚â§5 incompatible‚Ä¶ 
so stop searching the right branch; 
the value cannot come from there! MAX
MIN
value ‚â§6 
value‚â•7MIN
MAXb=6 ÔÅ°=-‚àû
ÔÅ°=7 b=+‚àûb=+‚àû ÔÅ°=6
b=5 ÔÅ°=-‚àû
incompatible‚Ä¶ 
so stop searching the right branch; 
the value cannot come from there! 32Alpha -Beta Pruning Algorithm
01 function alphabeta(node, depth, Œ±, Œ≤, maximizingPlayer)
02      if depth = 0 or node is a terminal node
03          return the heuristic value of node
04      if maximizingPlayer
05          v := -‚àû
06          for each child of node
07              v := max(v, alphabeta(child, depth -1, Œ±, Œ≤, FALSE))
08              Œ± := max(Œ±, v)
09              if Œ≤ ‚â§ Œ±
10                  break (* Œ≤ cut -off *)
11          return v
12      else
13          v := ‚àû
14          for each child of node
15              v := min(v, alphabeta(child, depth -1, Œ±, Œ≤, TRUE))
16              Œ≤ := min(Œ≤, v)
17              if Œ≤ ‚â§ Œ±
18                  break (* Œ± cut -off *)
19          return vInitial call:
alphabeta(origin, depth, -‚àû, +‚àû, TRUE)
source: http://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruningExample with tic -tac-toe
33min levelmax level
source: robotics.stanford.edu/~ latombe /cs121/2003/home.htmExample with tic -tac-toe
e(n) = 2
34max level
min level
value ‚â§2
source: robotics.stanford.edu/~ latombe /cs121/2003/home.htmb=2 ÔÅ°=-‚àûExample with tic -tac-toe
e(n) = 1 e(n) = 2
35value ‚â§2 1min levelmax level
source: robotics.stanford.edu/~ latombe /cs121/2003/home.htmb=2 1 ÔÅ°=-‚àûExample with tic -tac-toe
value ‚â•1
e(n) = 1value = 1
e(n) = 2
36min level
source: robotics.stanford.edu/~ latombe /cs121/2003/home.htmmax levelb=+‚àû ÔÅ°=1Example with tic -tac-toe
value‚â•1
e(n) = 1value = 1
e(n) = 2 e(n) = -1value‚â§-1 
37min levelmax level
source: robotics.stanford.edu/~ latombe /cs121/2003/home.htmb=+‚àû ÔÅ°=1
b=-1 ÔÅ°=-‚àûExample with tic -tac-toe
e(n) = 1b= 1
e(n) = 2 e(n) = -1value‚â§-1 
child Œ≤<= ancestor Œ±‚Üístop search
38incompatible‚Ä¶ 
so stop searching the right branch; 
the value cannot come from there! 
source: robotics.stanford.edu/~ latombe /cs121/2003/home.htmb=+‚àû ÔÅ°=1
b=-1 ÔÅ°=-‚àûvalue‚â•1Max
-------------------------------------------------------------------------------------------------------
Min
-------------------------------------------------------------------------------------------------------
Max
-------------------------------------------------------------------------------------------------------
Min
--------------------------------------------------------------------------------------------------------
39Alpha -Beta Pruning: Example 2
source: http://en.wikipedia.org/wiki/File:AB_pruning.svg‚â§5
=5 =6=5‚â•5
=7‚â§7
=4‚â§4‚â§4=5‚â§5 
=3=3=3=3‚â•3 
=6=6‚â•6
=6‚â§6‚â§6=6‚â§6
=7=7=7=6‚â•6 
=5=5=5‚â§5=6
‚úìxx‚úì‚úì x40Alpha -Beta Pruning: Example 2
source: http://en.wikipedia.org/wiki/File:AB_pruning.svgAlpha -Beta Pruning: Example 3
41Alpha -Beta Pruning: Example 3
42Alpha -Beta Pruning: Example 3
43<=4Alpha -Beta Pruning: Example 3
44<=3Alpha -Beta Pruning: Example 3
45<=3Alpha -Beta Pruning: Example 3
46=3Alpha -Beta Pruning: Example 3
47=3>=3Alpha -Beta Pruning: Example 3
48=3>=3Alpha -Beta Pruning: Example 3
49=3>=3
<=2Alpha -Beta Pruning: Example 3
50=3>=3
<=2pruneAlpha -Beta Pruning: Example 3
51=3=3Alpha -Beta Pruning: Example 3
52=3=3<=3Alpha -Beta Pruning: Example 3
53=3=3
<=4<=3Alpha -Beta Pruning: Example 3
54=3=3
<=2<=3Alpha -Beta Pruning: Example 3
55=3=3
=2<=3Alpha -Beta Pruning: Example 3
56=3=3
=2=2<=3Alpha -Beta Pruning: Example 3
57=3=3
=2=2<=2Alpha -Beta Pruning: Example 3
58=3=3
=2=2<=2
<=5Alpha -Beta Pruning: Example 3
59=3=3
=2=2<=2
=4Alpha -Beta Pruning: Example 3
60=3=3
=2=2<=2
=4>=4Alpha -Beta Pruning: Example 3
61=3=3
=2=2<=2
=4>=4pruneAlpha -Beta Pruning: Example 3
62=3=3
=2=2=2
=4Alpha -Beta Pruning: Example 3
63=3=3
=2=2=2
=4>=2Alpha -Beta Pruning: Example 3
64=3=3
=2=2=2
=4>=2Alpha -Beta Pruning: Example 3
65=3=3
=2=2=2
=4 <=1>=2prune
deep cut!Alpha -Beta Pruning: Example 3
66=3=3
=2=2=2
=4=1>=2
<=1prune
<=1
10 nodes explored out of 27 67Efficiency of Alpha -Beta Pruning
‚óºDepends on the order of the siblings
‚óºIn worst case: 
‚ùëalpha -beta provides no pruning
‚óºIn best case: 
‚ùëbranching factor is reduced to its square rootAlpha -Beta: Best ordering
68
Original (arbitrary) game tree
Best ordering for alpha -betaAlpha -Beta: Best ordering
‚óºbest ordering: 
1.children of MIN : smallest node first
2.children of MAX: largest node first
69
Alpha -Beta: Best ordering
‚óºbest ordering: 
1.children of MIN : smallest node first
2.children of MAX: largest node first
70
Alpha -Beta: Best ordering
71
‚óºbest ordering: 
1.children of MIN : smallest node first
2.children of MAX: largest node first
Alpha -Beta: Best ordering
72
Alpha -Beta: Best ordering
73
Alpha -Beta: Best ordering
74
8 nodes explored out of 27 75Today
‚óºState Space Search for Game Playing
‚ùëMiniMax
‚ùëAlpha -beta pruning
‚ùëStochastic Games
‚óºWhere we are today
Backgammon
source: Russel & Norvig (2010) 
Stochastic (Non -Deterministic)
Games
‚óºSearch tree for games of chance 
‚ùëwhite can calculate its own legal moves
‚ùëbut it does not know what black will roll...
‚óºIdea: add chance nodes to the search tree
‚ùëbranches indicate possible dice rolls
‚ùëeach branch labeled with the roll and its probability
(e.g., 1/6 for a single dice roll)Search Tree for Backgammon
EXPECTIMINIMAX Algorithm
‚óºCalculating E XPECTIMINIMAX
‚ùëLike MiniMax, but using the weighted sum for Chance nodes:
‚ùër is a possible dice roll (or other random event)
‚ùëP(r) the probability of the event
‚ùëResult(s, r) is the same state s with dice roll result r
‚ùëNote: very expensive due to the high branching factor!
‚ùëSee https://en.wikipedia.org/wiki/Expectiminimax
for the whole algorithm‡∑çùëÉùëüùê∏ùë•ùëùùëíùëêùë°ùëñùëöùëñùëõùëñùëöùëéùë• ùëÖùëíùë†ùë¢ùëôùë°ùë†,ùëü84Today
‚óºState Space Search for Game Playing
‚ùëMiniMax
‚ùëAlpha -beta pruning
‚ùëStochastic Games
‚óºWhere we are today
1992 -1994 -Checkers: 
Tinsley vs. ChinookMarion Tinsley
World champion 
for over 40 years
In 2007, Schaeffer announced that checkers was solved, 
and anyone playing against Chinook would only be able to draw, never win.
Chinook
Developed by
Jonathan Schaeffer, 
professor at the U. of Alberta
1992: Tinsley beat Chinook in 4 games to 2, 
with 33 draws. 
1994: 6 draws  VS
85Play against Chinook: http ://games.cs.ualberta.ca/cgi -bin/player.cgi?nodemo1997 -Othello: Murakami vs. Logistello
Logistello beat Murakami by 6 games to 0
Takeshi Murakami
World Othello (aka Reversi) champion
VS
Logistello
developed by Michael Buro
runs on a standard PC
https://skatgame.net/mburo/log.html
(including source code)
861997 -Chess: Kasparov vs. Deep Blue
Garry Kasparov
50 billion neurons
2 positions/sec
VS
Deep Blue
32 RISC processors 
+ 256 VLSI chess engines
200,000,000 pos/sec
Deep Blue wins by 3 wins, 1 loss, and 2 draws
872003 -Chess: Kasparov vs. Deep Junior
Match ends in a 3/3 tie!Garry Kasparov
still 50 billion neurons
still 2 positions/sec
VS
Deep Junior
8 CPU, 8 GB RAM, Win 2000 
2,000,000 pos/sec
Available at $100
88892016 ‚ÄìGo: AlphaGo vs Lee Se -dol
‚óºGO was always considered a much harder game to automate 
than chess because of its very high branching factor (35 for 
chess vs 250 for Go!)
https://www.theverge.com/2016/3/15/11213518/alphago -deepmind -go-match -5-result‚óºIn 2016, AlphaGo beat Lee Sedol in a 
five-game match of GO.  
‚óºIn 2017 AlphaGo beat Ke Jie, the 
world No.1 ranked player at the time
‚óºuses a Monte Carlo tree search 
algorithm to find its moves based on 
knowledge previously "learned" by deep 
learning902017 ‚ÄìAlphaGo Zero & AlphaZero
AlphaGo Zero learned the Game by itself, without input of human 
games
‚óºBecame better than all old versions after 40 days of training
‚óºIn the first three days, AlphaGo Zero played 4.9 million games 
against itself using reinforcement learning
AlphaZero can learn other 
games, like Chess and Shogi
‚óºIn 2018, it beat the then -
best chess program, 
Stockfish 8 in a 100 -game 
tournament
‚óºTrained using 5,000 tensor 
processing units (TPUs), run 
on four TPUs and a 44 -core 
CPU during matches
912018 ‚ÄìAlphaZero vs Stockfish 8
Game commentary: https://www.youtube.com/watch?v=nPexHaFL1uo92Today
‚óºState Space Search for Game Playing
‚ùëMiniMax
‚ùëAlpha -beta pruning
‚ùëStochastic games
‚óºWhere we are today
